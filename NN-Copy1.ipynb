{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    train_mnist=\"./MNIST/mnist_train.csv\"\n",
    "    test_mnist=\"./MNIST/mnist_test.csv\"\n",
    "    train_data=np.loadtxt(fname=train_mnist,delimiter=',')\n",
    "    test_data=np.loadtxt(fname=test_mnist,delimiter=',')\n",
    "    train_label=train_data[:,0]\n",
    "    all_train_data=train_data[:,1:]\n",
    "    test_label=test_data[:,0]\n",
    "    all_test_data=test_data[:,1:]\n",
    "    train_label_1ofK=np.identity(10)[train_label.astype(np.int)]\n",
    "    test_label_1ofK=np.identity(10)[test_label.astype(np.int)]\n",
    "    \n",
    "    return (train_label_1ofK,all_train_data/255,test_label_1ofK,all_test_data/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "dif_relu=lambda x:np.where(x>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vin):\n",
    "    cor=np.max(vin)\n",
    "    vout=np.exp(vin-cor)/np.tile(np.sum(np.exp(vin-cor),axis=1),(10,1)).T\n",
    "    return vout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(x,t):\n",
    "    return -1*np.sum(t*np.log(x))/t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(x,gamma,beta,eps):\n",
    "    N,D=x.shape\n",
    "    mu=1./N*np.sum(x,axis=0)\n",
    "    xmu=x-mu\n",
    "    sq=xmu**2\n",
    "    var=1./N*np.sum(sq,axis=0)\n",
    "    sqrtvar=np.sqrt(var+eps)\n",
    "    ivar=1./sqrtvar\n",
    "    xhat=xmu*ivar\n",
    "    gammax=gamma*xhat\n",
    "    out=gammax+beta\n",
    "    cache=(xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "    return out,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_backward(dout,cache):\n",
    "    xhat,gamma,xmu,ivar,sqrtvar,var,eps=cache\n",
    "    N,D=dout.shape\n",
    "    dbeta=np.sum(dout,axis=0)\n",
    "    dgammax=dout\n",
    "    dgamma=np.sum(dgammax*xhat,axis=0)\n",
    "    dxhat=dgammax*gamma\n",
    "    divar=np.sum(dxhat*xmu,axis=0)\n",
    "    dxmu1=dxhat*ivar\n",
    "    dsqrtvar=-1./(sqrtvar**2)*divar\n",
    "    dvar=0.5*1./np.sqrt(var+eps)*dsqrtvar\n",
    "    dsq=1./N*np.ones((N,D))*dvar\n",
    "    dxmu=2*xmu*dsq\n",
    "    dx1=(dxmu1+dxmu2)\n",
    "    dmu=1.*np.sum(dxmu1+dxmu2,axis=0)\n",
    "    dx2=1./N*np.ones((N,D))*dmu\n",
    "    dx=dx1+dx2\n",
    "    return dx,dgamma,dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, input_size,hidden_size,output_size,batch_size):\n",
    "        self.W1=0.2*(np.random.rand(input_size,hidden_size)-0.5)\n",
    "        self.W2=0.2*(np.random.rand(hidden_size,output_size)-0.5)\n",
    "        self.b1=np.zeros(hidden_size)\n",
    "        self.b2=np.zeros(output_size)\n",
    "        self.z1=None\n",
    "        self.z2=None\n",
    "        self.batch_size=batch_size\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        self.grad_b1=np.empty(hidden_size)\n",
    "        self.grad_b2=np.empty(output_size)\n",
    "        self.grad_W1=np.empty((input_size,hidden_size))\n",
    "        self.grad_W2=np.empty((hidden_size,output_size))\n",
    "        #self.beta=None\n",
    "        #self.dbeta=None\n",
    "        #self.gamma=None\n",
    "        #self.dgamma=None\n",
    "        #self.eps=None\n",
    "        \n",
    "    def bn_forward(self,x):\n",
    "        gamma=1\n",
    "        beta=0\n",
    "        eps=10e-7\n",
    "        out=np.dot(x, self.W1) - self.b1\n",
    "        out=batchnorm_forward(out,gamma,beta,eps)\n",
    "        self.z1=relu(out)\n",
    "        out=np.dot(self.z1,self.W2) - self.b2\n",
    "        out=batchnorm_forward(out,gamma,beta,eps)\n",
    "        self.z2=softmax(out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.z1=relu(np.dot(x, self.W1) - self.b1)\n",
    "        self.z2=softmax(np.dot(self.z1,self.W2) - self.b2)\n",
    "        \n",
    "    def bn_calc_grad(self,input_data,teaching_data):\n",
    "        self.bn_forward(input_data)\n",
    "        cross_entropy_error=cross_entropy(self.z2,teaching_data)\n",
    "        cross_entropy_error,dgamma,dbeta=batchnorm_backward(self.z2,cache)\n",
    "        delta2=self.z2-teaching_data\n",
    "        delta1=dif_relu(self.z1)*np.dot(delta2,self.W2.T)\n",
    "        self.grad_b1=-1*np.sum(delta1,axis=0)/self.batch_size\n",
    "        self.grad_b2=-1*np.sum(delta2,axis=0)/self.batch_size\n",
    "        self.grad_W1=np.dot(input_data.T,delta1)\n",
    "        self.grad_W2=np.dot(self.z1.T,delta2)\n",
    "        return cross_entropy_error,dgamma,dbeta\n",
    "    \n",
    "    def calc_grad(self,input_data,teaching_data):\n",
    "        self.forward(input_data)\n",
    "        cross_entropy_error=cross_entropy(self.z2,teaching_data)\n",
    "        delta2=self.z2-teaching_data\n",
    "        delta1=dif_relu(self.z1)*np.dot(delta2,self.W2.T)\n",
    "        self.grad_b1=-1*np.sum(delta1,axis=0)/self.batch_size\n",
    "        self.grad_b2=-1*np.sum(delta2,axis=0)/self.batch_size\n",
    "        self.grad_W1=np.dot(input_data.T,delta1)\n",
    "        self.grad_W2=np.dot(self.z1.T,delta2)\n",
    "        return cross_entropy_error\n",
    "    \n",
    "    def backward(self,rate):\n",
    "        self.b1-=rate*self.grad_b1\n",
    "        self.b2-=rate*self.grad_b2\n",
    "        self.W1-=rate*self.grad_W1\n",
    "        self.W2-=rate*self.grad_W2\n",
    "        self.gamma-=rate*dgamma\n",
    "        self.beta-=rate*dbeta\n",
    "        \n",
    "    def calc_accuracy(self,input_data,teaching_data):\n",
    "        self.bn_forward(input_data)\n",
    "        arg_z2=np.argmax(self.z2,axis=1)\n",
    "        arg_z2_1ofK=np.identity(10)[arg_z2.astype(np.int)]\n",
    "        return np.sum(arg_z2_1ofK*teaching_data)/self.batch_size\n",
    "    \n",
    "    def parameter_output(self):\n",
    "        file_b1=\"./parameter/b1.csv\"\n",
    "        file_b2=\"./parameter/b2.csv\"\n",
    "        file_W1=\"./parameter/W1.csv\"\n",
    "        file_W2=\"./parameter/W2.csv\"\n",
    "        np.savetxt(fname=file_b1,X=self.b1,delimiter=',')\n",
    "        np.savetxt(fname=file_b2,X=self.b2,delimiter=',')\n",
    "        np.savetxt(fname=file_W1,X=self.W1,delimiter=',')\n",
    "        np.savetxt(fname=file_W2,X=self.W2,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileloadCompleted\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-52e262a24c43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-52e262a24c43>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx_train_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoices_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNeural_Network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_calc_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_train_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mNeural_Network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9c39a89bf5d4>\u001b[0m in \u001b[0;36mbn_calc_grad\u001b[1;34m(self, input_data, teaching_data)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbn_calc_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mteaching_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mteaching_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchnorm_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9c39a89bf5d4>\u001b[0m in \u001b[0;36mbn_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchnorm_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchnorm_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-b023cd182913>\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdif_relu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_N=784\n",
    "    hidden_N=200\n",
    "    output_N=10\n",
    "    batch_N=100\n",
    "    learning_rate=0.01\n",
    "    epoch=100\n",
    "\n",
    "    parameter_output=False\n",
    "    accuracy_output=False\n",
    "    t_train,x_train,t_test,x_test=get_mnist()\n",
    "    print(\"FileloadCompleted\")\n",
    "    \n",
    "    train_data_N=t_train.shape[0]\n",
    "    Neural_Network=NN(input_size=input_N,hidden_size=hidden_N,output_size=output_N,batch_size=batch_N)\n",
    "    updates=train_data_N//batch_N+1\n",
    "    epoch_cnt=0\n",
    "    acc_err=[]\n",
    "    \n",
    "    for i in range (epoch*updates):\n",
    "        choices_train=np.random.randint(0,train_data_N-1,batch_N)\n",
    "        t_train_batch=t_train[choices_train]\n",
    "        x_train_batch=x_train[choices_train]\n",
    "        \n",
    "        loss=Neural_Network.bn_calc_grad(x_train_batch,t_train_batch)\n",
    "        Neural_Network.backward(learning_rate)\n",
    "        if (i+1)%updates ==0 or i==0:\n",
    "            accuracy=Neural_Network.calc_accuracy(x_test,t_test)\n",
    "            print(\"accuracy\",[epoch_cnt],\"=\",accuracy)\n",
    "            print(\"loss=\",loss)\n",
    "            print()\n",
    "            epoch_cnt+=1\n",
    "            acc_err.append([accuracy,loss])\n",
    "    if parameter_output : Neural_Network.parameter_output()\n",
    "    if accuracy_output : np.savetxt(fname=\"./accuracy.csv\",X=acc_err,delimiter=',')\n",
    "            \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
